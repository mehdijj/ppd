{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attacking PPD trained on MNIST\n",
    "===\n",
    "This Notebook loads trained PPD models on MNIST dataset, Ensembles them and generates adversarial examples using different attacks.\n",
    "\n",
    "The models are loaded from saved_models >> mnistdense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is needed because before loading the trained models, the graph should be loaded with the same\n",
    "# structure as it was trained.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import functools\n",
    "from cleverhans.model import Model\n",
    "\n",
    "\n",
    "# ______________________________________ content of my local utils_tf.py _______________________________\n",
    "def fftshift(inputs):\n",
    "    \"\"\"\n",
    "    Calculates and returns fftshift of the inputs tensor along second and third axes.\n",
    "    :param inputs: Tensor with shape (None, ., ., .)\n",
    "    :return: a Tensor which is fftshift of inputs along second and third axes with same dtype and shape\n",
    "    \"\"\"\n",
    "    axes = range(1, len(inputs.shape) - 1)\n",
    "    for k in axes:\n",
    "        n = inputs.shape[k]\n",
    "        p2 = (n + 1) // 2\n",
    "        my_list = tf.concat((tf.range(p2, n), tf.range(p2)), axis=0)\n",
    "        inputs = tf.gather(inputs, my_list, axis=k)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def pixel2phase(inputs):\n",
    "    \"\"\"\n",
    "    convert the inputs images to the phase domain along each channel.\n",
    "    :param inputs: Tensor with shape (None, height, width, channels)\n",
    "    :return: Tensor with same shape and dtype as inputs\n",
    "    \"\"\"\n",
    "    inputs_dtype = inputs.dtype\n",
    "    dtype = tf.complex64\n",
    "    inputs = tf.cast(inputs, dtype=dtype)\n",
    "    input_f = fftshift(tf.transpose(tf.fft2d(tf.transpose(inputs, perm=[0, 3, 1, 2])), perm=[0, 2, 3, 1]))\n",
    "    input_f = tf.where(tf.less(tf.abs(input_f), 1e-5), tf.zeros(tf.shape(input_f), dtype=dtype), input_f)\n",
    "    return tf.cast(tf.angle(input_f), dtype=inputs_dtype)\n",
    "#_______________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "#________________________________________content of my local model_structure.py ________________________\n",
    "class ModelDense(Model):\n",
    "    def __init__(self, scope, nb_classes, reg, **kwargs):\n",
    "        del kwargs\n",
    "        Model.__init__(self, scope, nb_classes, locals())\n",
    "        self.reg = reg\n",
    "\n",
    "    def fprop(self, x, **kwargs):\n",
    "        del kwargs\n",
    "        my_conv = functools.partial(tf.layers.dense, activation=tf.nn.relu,\n",
    "                                    kernel_regularizer=tf.contrib.layers.l2_regularizer(self.reg),\n",
    "                                    kernel_initializer=HeReLuNormalInitializer,\n",
    "                                    )\n",
    "        with tf.variable_scope(self.scope, reuse=tf.AUTO_REUSE):\n",
    "            y = pixel2phase(x)\n",
    "            y = tf.layers.flatten(y)\n",
    "            y = my_conv(y, 800)\n",
    "            y = my_conv(y, 300)\n",
    "\n",
    "            logits = tf.layers.dense(y, self.nb_classes,\n",
    "                                     kernel_regularizer=tf.contrib.layers.l2_regularizer(self.reg),\n",
    "                                     kernel_initializer=HeReLuNormalInitializer)\n",
    "            return {self.O_LOGITS: logits,\n",
    "                    self.O_PROBS: tf.nn.softmax(logits=logits)}\n",
    "\n",
    "\n",
    "class HeReLuNormalInitializer(tf.initializers.random_normal):\n",
    "    def __init__(self, dtype=tf.float32):\n",
    "        self.dtype = tf.as_dtype(dtype)\n",
    "\n",
    "    def get_config(self):\n",
    "        return dict(dtype=self.dtype.name)\n",
    "\n",
    "    def __call__(self, shape, dtype=None, partition_info=None):\n",
    "        del partition_info\n",
    "        dtype = self.dtype if dtype is None else dtype\n",
    "        std = tf.rsqrt(tf.cast(tf.reduce_prod(shape[:-1]), tf.float32) + 1e-7)\n",
    "        return tf.random_normal(shape, stddev=std, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _________________________________________ content of utils.py ______________________________\n",
    "def _permute_index(l, seed):\n",
    "    \"\"\"\n",
    "    Creates a permutation of np.array([0, ..., l-1]) and its inverse\n",
    "    :param l: length of the array to permute\n",
    "    :param seed: permutation seed\n",
    "    :return: (s, s_inverse) where s is permutation of np.array([0, ..., l-1]) and s_inverse is its inverse\n",
    "    \"\"\"\n",
    "    st0 = np.random.get_state()\n",
    "    s = np.arange(l)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(s)\n",
    "    s_inverse = np.argsort(s)\n",
    "    np.random.set_state(st0)\n",
    "    return s, s_inverse\n",
    "\n",
    "\n",
    "def permute(data, seed):\n",
    "    \"\"\"\n",
    "    Permutes images in the data with given seed for each channel.\n",
    "    :param data: numpy array with shape (nb_images, img_rows, img_cols, nb_channels)\n",
    "    :param seed: permutation seed. If seed=None returns data without permutation\n",
    "    :return: numpy array with shape (nb_images, img_rows, img_cols, nb_channels) of permuted images\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Permutes images in the data with given seed. If seed=None, returns data without permutation.\n",
    "    Assumes data has shape (nb_images, img_rows, img_cols, nb_channels)\n",
    "    \"\"\"\n",
    "    nb_images, img_rows, img_cols, nb_channels = data.shape\n",
    "    if seed is None:\n",
    "        return data\n",
    "    l = img_rows * img_cols  # length of the permutation array\n",
    "    s, _ = _permute_index(l, seed)\n",
    "    output = np.zeros(data.shape)\n",
    "    for ch in range(nb_channels):\n",
    "        output[:, :, :, ch] = data[:, :, :, ch].reshape(-1, l)[:, s].reshape(-1, img_rows, img_cols)\n",
    "    return output\n",
    "\n",
    "\n",
    "def ipermute(data, seed):\n",
    "    \"\"\"\n",
    "    inverse of permute\n",
    "    :param data: numpy array with shape (nb_images, img_rows, img_cols, nb_channels)\n",
    "    :param seed:  permutation seed. If seed=None returns data without permutation\n",
    "    :return: numpy array with shape (nb_images, img_rows, img_cols, nb_channels) of inverse permuted images\n",
    "    \"\"\"\n",
    "    nb_images, img_rows, img_cols, nb_channels = data.shape\n",
    "    if seed is None:\n",
    "        return data\n",
    "    l = img_rows * img_cols  # length of the permutation array\n",
    "    _, s_inverse = _permute_index(l, seed)\n",
    "    output = np.zeros(data.shape)\n",
    "    for ch in range(nb_channels):\n",
    "        output[:, :, :, ch] = data[:, :, :, ch].reshape(-1, l)[:, s_inverse].reshape(-1, img_rows, img_cols)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_attack(attack_name, adv_x, perturbation_strength, attack_params):\n",
    "    \"\"\"\n",
    "    saves adv_x with name perturbaton_strength in subfolder with attack_name\n",
    "    \"\"\"\n",
    "    directory = os.path.join('Attack Logs', attack_name)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    import json\n",
    "    with open(os.path.join(directory, 'params' + str(perturbation_strength) + '.txt'), 'w') as file:\n",
    "        file.write(json.dumps(attack_params)) # use `json.loads` to do the reverse\n",
    "    np.save(os.path.join(directory, str(perturbation_strength)), adv_x)\n",
    "\n",
    "\n",
    "def _read_attack(attack_name, perturbation_strength):\n",
    "    \"\"\"\n",
    "    loads adv_x with name perturbaton_strength in subfolder with attack_name\n",
    "    :param attack_name: string of attack name used for folder to save\n",
    "    :param perturbation_strength: a float or string of attack file\n",
    "    \"\"\"\n",
    "    filename = os.path.join('Attack Logs', attack_name, str(perturbation_strength) + '.npy')\n",
    "    return np.load(filename)\n",
    "\n",
    "def read_attack(attack_name):\n",
    "    directory = os.path.join('Attack Logs', attack_name)\n",
    "    out = dict()\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.npy'):\n",
    "            path_to_file = os.path.join(directory, filename)\n",
    "            out[np.float(os.path.splitext(filename)[0])] = np.load(path_to_file)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_perturbation(x, adv_x, order):\n",
    "    \"\"\"\n",
    "    average perturbation between x and adv_x. Note that each image is converted to\n",
    "    a vector of size (img_rows*img_cols*nb_channels) and then norm is calculated.\n",
    "    :param x: numpy array with shape (nb_images, img_rows, img_cols, nb_channels)\n",
    "    :param adv_x: numpy array with same shape as x\n",
    "    :param order: order of the norm (mimics numpy) possible values are np.inf, 1 or 2\n",
    "    :return: a scalar denoting perturbation between x and adv_x averaged over images.\n",
    "    \"\"\"\n",
    "    nb_images, _, _, _ = x.shape\n",
    "    dev = (x-adv_x).reshape(nb_images, -1)\n",
    "    dev_norms = np.linalg.norm(dev, order, axis=1)\n",
    "    return np.mean(dev_norms)\n",
    "\n",
    "def random_perturb(x, perturbation_strength, order):\n",
    "    \"\"\"\n",
    "    randomly perturbes pixels of x with perturbation_strength such that \n",
    "    measure_perturbation(x, random_perturb(x, perturbation_strength, order), order) = perturbation_strength.\n",
    "    For order=np.inf each pixel is perturbed with either -perturbation_strenth or perturbation_strength.\n",
    "    For order = 1 and order = 2, images of the pixel are perturbed with a uniform random noise with mean zero.\n",
    "    :param x: numpy array with shape (nb_images, img_rows, img_cols, nb_channels)\n",
    "    :param perturbation_strength: a scalar that is strength of noise.\n",
    "    :param order: order of the norm (mimics numpy) possible values are np.inf, 1 or 2\n",
    "    :return: numpy array with same shape as x which denotes random perturbation of pixels of x with perturbation_strength\n",
    "    \"\"\"\n",
    "    nb_images, img_rows, img_cols, nb_channels = x.shape\n",
    "    if order == np.inf:\n",
    "        dev = (np.random.randint(0, 2, size=nb_images*img_rows*img_cols*nb_channels) * 2 * perturbation_strength - perturbation_strength)\n",
    "    elif order == 1:\n",
    "        tmp = np.random.rand(nb_images, img_rows*img_cols*nb_channels) - 0.5\n",
    "        coef = perturbation_strength / np.sum(np.abs(tmp), axis=1)\n",
    "        dev = tmp * np.expand_dims(coef, axis=1)\n",
    "    elif order == 2:\n",
    "        tmp = np.random.rand(nb_images, img_rows*img_cols*nb_channels) - 0.5\n",
    "        coef = perturbation_strength / np.linalg.norm(tmp, 2, axis=1)\n",
    "        dev = tmp * np.expand_dims(coef, axis=1)\n",
    "    else:\n",
    "        raise(ValueError('order should be np.inf, 1 or 2'))\n",
    "    return x + dev.reshape(x.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_plot_data(attack_name, header, arr):\n",
    "    \"\"\"\n",
    "    concatenates numpy arrays in arr and saves them as 'plot_data.csv'.\n",
    "    :param attack_name: string of attack name (the folder in which data is to be logged)\n",
    "    :param header: list of strings denoting header name for element of arr\n",
    "    :param arr: list of numpy arrays to be logged. For example: [strength, adv_acc, ...]\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    directory = os.path.join('Attack Logs', attack_name)\n",
    "    tmp = np.concatenate(tuple([np.array(a).reshape(-1, 1) for a in arr]), axis=1)\n",
    "    df = pd.DataFrame(tmp, columns=header)\n",
    "    df.to_csv(os.path.join(directory, 'plot_data'), index=False)\n",
    "    \n",
    "def load_plot_data(attack_name):\n",
    "    \"\"\"\n",
    "    reads data saved with log_plot_data\n",
    "    :param attack_name: string of attack name (the folder to read from)\n",
    "    :return: a pandas dataFrame containing plot data.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    path = os.path.join('Attack Logs', attack_name, 'plot_data')\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.utils_tf import tf_model_load\n",
    "class Ensemble(object):\n",
    "    \n",
    "    def __init__(self, seeds, directory, model_class, **kwargs):\n",
    "        \n",
    "        self.img_rows = kwargs.get('img_rows', 28)\n",
    "        self.img_cols = kwargs.get('img_cols', 28)\n",
    "        self.nb_channels = kwargs.get('nb_channels', 1)\n",
    "        self.nb_classes = kwargs.get('nb_classes', 10)\n",
    "        self.reg = kwargs.get('reg', 5e-3)\n",
    "        self.scope = kwargs.get('scope', 'model1')\n",
    "        \n",
    "        self.seeds = seeds\n",
    "        self.directory = directory\n",
    "        self.model_class = model_class\n",
    "        self.sessions_dict, self.models_dict, self.placeholders_dict = self.load_models()\n",
    "                \n",
    "    def load_models(self):\n",
    "        sessions_dict = dict()\n",
    "        models_dict = dict()\n",
    "        placeholders_dict = dict()\n",
    "        for seed in self.seeds:\n",
    "            sess = tf.Session(graph=tf.Graph())\n",
    "            with sess.graph.as_default():\n",
    "                # ____________________ defining the model graph ________________________\n",
    "                x = tf.placeholder(tf.float32, shape=(None, self.img_rows, self.img_cols, self.nb_channels))\n",
    "                model = self.model_class(scope=self.scope, nb_classes=self.nb_classes, reg=self.reg)\n",
    "                preds = model.get_logits(x)\n",
    "                # ______________________________________________________________________\n",
    "                \n",
    "                model_path = os.path.join(self.directory, str(seed), 'mnist')\n",
    "                if os.path.exists(model_path  + \".meta\"):\n",
    "                    tf_model_load(sess, model_path)\n",
    "                sessions_dict[seed] = sess\n",
    "                models_dict[seed] = model\n",
    "                placeholders_dict[seed] = x\n",
    "        return sessions_dict, models_dict, placeholders_dict\n",
    "    \n",
    "    def predict(self, unpermuted_pixel_data, seeds=None):\n",
    "        if seeds is None:\n",
    "            seeds = self.seeds\n",
    "        total_pred = 0\n",
    "        for seed in seeds:\n",
    "            sess = self.sessions_dict[seed]\n",
    "            with sess.graph.as_default():\n",
    "                model = self.models_dict[seed]\n",
    "                x = self.placeholders_dict[seed]\n",
    "                preds = model.get_probs(x)\n",
    "                total_pred += sess.run(preds, feed_dict={x: permute(unpermuted_pixel_data, seed=seed)})\n",
    "        return total_pred/len(seeds)\n",
    "                \n",
    "    def get_model(self, seed):\n",
    "        return self.models_dict[seed], self.sessions_dict[seed], self.placeholders_dict[seed]\n",
    "    \n",
    "    def accuracy_plot(self, unpermuted_pixel_data, true_labels, seeds=None):\n",
    "        if seeds is None:\n",
    "            seeds = self.seeds\n",
    "        out = []\n",
    "        total_pred = 0\n",
    "        for seed in seeds:\n",
    "            sess = self.sessions_dict[seed]\n",
    "            with sess.graph.as_default():\n",
    "                model = self.models_dict[seed]\n",
    "                x = self.placeholders_dict[seed]\n",
    "                preds = model.get_probs(x)\n",
    "                total_pred += sess.run(preds, feed_dict={x: permute(unpermuted_pixel_data, seed=seed)})\n",
    "                p = total_pred/(len(out) + 1)\n",
    "                out.append(np.mean(np.equal(np.argmax(p, axis=1), np.argmax(true_labels, axis=1))))\n",
    "        return out\n",
    "        \n",
    "    \n",
    "    def accuracy(self, unpermuted_pixel_data, true_labels, seeds=None):\n",
    "        return np.mean(np.equal(np.argmax(self.predict(unpermuted_pixel_data, seeds=seeds), axis=1), np.argmax(true_labels, axis=1)))\n",
    "        \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    'img_rows': 28,\n",
    "    'img_cols': 28,\n",
    "    'nb_channels': 1,\n",
    "    'nb_classes': 10\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    'scope': 'model1',\n",
    "    'reg': 5e-3\n",
    "}\n",
    "\n",
    "eval_params = {\n",
    "    'batch_size': 128\n",
    "}\n",
    "\n",
    "ensemble_params = deepcopy(dataset_params)\n",
    "ensemble_params.update(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape = (60000, 28, 28, 1)\n",
      "y_train shape = (60000, 10)\n",
      "x_test shape = (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, axis=3).astype('float32')/255\n",
    "x_test = np.expand_dims(x_test, axis=3).astype('float32')/255\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, dataset_params['nb_classes'])\n",
    "y_test = tf.keras.utils.to_categorical(y_test, dataset_params['nb_classes'])\n",
    "print(\"x_train shape =\", x_train.shape)\n",
    "print(\"y_train shape =\", y_train.shape)\n",
    "print (\"x_test shape =\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/100/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/101/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/102/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/103/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/104/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/105/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/106/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/107/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/108/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/109/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/110/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/111/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/112/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/113/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/114/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/115/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/116/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/117/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/118/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/119/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/120/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/121/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/122/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/123/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/124/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/125/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/126/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/127/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/128/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/129/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/130/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/131/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/132/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/133/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/134/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/135/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/136/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/137/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/138/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/139/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/140/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/141/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/142/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/143/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/144/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/145/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/146/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/147/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/148/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/149/mnist\n",
      "INFO:tensorflow:Restoring parameters from saved_models/mnistdense/150/mnist\n"
     ]
    }
   ],
   "source": [
    "seeds = range(100, 151) # before loading models they should be trained and saved using main_mnist.py\n",
    "directory = os.path.join('saved_models', 'mnistdense')\n",
    "ensemble = Ensemble(seeds=seeds, directory=directory, model_class=ModelDense, **ensemble_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ensemble.accuracy_plot(x_test, y_test)\n",
    "# acc = ensemble.accuracy(x_test, y_test, seeds=range(100, 150)) # if seeds=None, accuracy on all the ensembled models is provided. if a list\n",
    "# of models is provided as seeds (for example seeds=[100, 101, 102]) ensemble of accuracy on models in seeds is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c556e2290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(out)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FGSM\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing FGSM attack\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils_tf import model_eval\n",
    "\n",
    "seed = 100 # model for which attack is performed\n",
    "model, sess, x = ensemble.get_model(seed)\n",
    "\n",
    "nb_attacked_images = 100\n",
    "fgsm_params = {\n",
    "        'eps': 3.992,\n",
    "        'ord': 2\n",
    "        }\n",
    "print('Attacking model {0} ...'.format(seed))\n",
    "fgsm = FastGradientMethod(model, sess=sess)\n",
    "with sess.graph.as_default():\n",
    "    y = tf.placeholder(tf.float32, shape=(None, dataset_params['nb_classes']))\n",
    "    adv_x_fgsm = ipermute(fgsm.generate_np(permute(x_test[0:nb_attacked_images], seed), **fgsm_params), seed)\n",
    "    preds = model.get_logits(x)\n",
    "adv_acc = model_eval(sess, x, y, preds, permute(adv_x_fgsm, seed=seed), y_test[0:nb_attacked_images], args=eval_params)\n",
    "print('Accuracy on model {0}:'.format(seed), adv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average l_2 norm perturbation of adversarial examples: 3.99200015284089\n"
     ]
    }
   ],
   "source": [
    "order = 2\n",
    "perturbation_strength = measure_perturbation(x_test[0:nb_attacked_images], adv_x_fgsm, order=order)\n",
    "print('Average l_{0} norm perturbation of adversarial examples:'.format(order), perturbation_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_attack(attack_name='fgml2', adv_x=adv_x_fgsm, perturbation_strength=perturbation_strength, attack_params=fgsm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CW Attack\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on model 100: 0.6407\n"
     ]
    }
   ],
   "source": [
    "# performing CW attack\n",
    "from cleverhans.attacks import CarliniWagnerL2\n",
    "from cleverhans.utils_tf import model_eval\n",
    "\n",
    "seed = 100 # model for which attack is performed\n",
    "model, sess, x = ensemble.get_model(seed)\n",
    "\n",
    "nb_attacked_images = 10000\n",
    "cw_params = {'binary_search_steps': 1,\n",
    "             'max_iterations': 300,\n",
    "             'learning_rate': 0.1, # it was .005\n",
    "             'initial_const': 10, # it was 0.01\n",
    "             'batch_size' : 1,\n",
    "             'confidence': 0,\n",
    "             'abort_early': True}\n",
    "\n",
    "cw = CarliniWagnerL2(model, sess=sess)\n",
    "with sess.graph.as_default():\n",
    "    y = tf.placeholder(tf.float32, shape=(None, dataset_params['nb_classes']))    \n",
    "    adv_x_cw = ipermute(cw.generate_np(permute(x_test[0:nb_attacked_images], seed=seed), **cw_params), seed=seed)\n",
    "    preds = model.get_logits(x)\n",
    "adv_acc = model_eval(sess, x, y, preds, permute(adv_x_cw[0:nb_attacked_images], seed=seed), y_test[0:nb_attacked_images], args=eval_params)\n",
    "print('Accuracy on model {0}:'.format(seed), adv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average l_2 norm perturbation of adversarial examples: 1.5182444231630907\n"
     ]
    }
   ],
   "source": [
    "order = 2\n",
    "perturbation_strength = measure_perturbation(x_test[0:nb_attacked_images], adv_x_cw, order=order)\n",
    "print('Average l_{0} norm perturbation of adversarial examples:'.format(order), perturbation_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_attack(attack_name='cwl2', adv_x=adv_x_cw, perturbation_strength=perturbation_strength, attack_params=cw_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PGD\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on model 100: 0.9557\n"
     ]
    }
   ],
   "source": [
    "from cleverhans.attacks import MadryEtAl\n",
    "from cleverhans.utils_tf import model_eval\n",
    "\n",
    "seed = 100 # model for which attack is performed\n",
    "model, sess, x = ensemble.get_model(seed)\n",
    "\n",
    "nb_attacked_images = 10000\n",
    "pgd_params = {'eps': 1.074, # madry 0.3\n",
    "              'eps_iter': 0.1, # madry 0.01\n",
    "              'nb_iter': 200, # madry 100\n",
    "              'ord': 2\n",
    "             }\n",
    "\n",
    "pgd = MadryEtAl(model, sess=sess)\n",
    "with sess.graph.as_default():\n",
    "    y = tf.placeholder(tf.float32, shape=(None, dataset_params['nb_classes']))\n",
    "    adv_x_pgd = ipermute(pgd.generate_np(permute(x_test[0:nb_attacked_images], seed=seed), **pgd_params), seed=seed)\n",
    "    preds = model.get_logits(x)\n",
    "adv_acc = model_eval(sess, x, y, preds, permute(adv_x_pgd, seed=seed), y_test[0:nb_attacked_images], args=eval_params)\n",
    "print('Accuracy on model {0}:'.format(seed), adv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average l_2 norm perturbation of adversarial examples: 3.9900000443803396\n"
     ]
    }
   ],
   "source": [
    "order = pgd_params['ord']\n",
    "perturbation_strength = measure_perturbation(x_test[0:nb_attacked_images], adv_x_pgd, order=order)\n",
    "print('Average l_{0} norm perturbation of adversarial examples:'.format(order), perturbation_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_attack(attack_name='pgdl2', adv_x=adv_x_pgd, perturbation_strength=perturbation_strength, attack_params=pgd_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIM\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on model 100: 0.95\n"
     ]
    }
   ],
   "source": [
    "from cleverhans.attacks import MomentumIterativeMethod\n",
    "from cleverhans.utils_tf import model_eval\n",
    "\n",
    "seed = 100 # model for which attack is performed\n",
    "model, sess, x = ensemble.get_model(seed)\n",
    "\n",
    "nb_attacked_images = 100\n",
    "mim = MomentumIterativeMethod(model, sess=sess)\n",
    "mim_params = {'eps_iter': 0.01,\n",
    "              'nb_iter': 100,\n",
    "              'decay_factor': 1,\n",
    "              'eps': .3}\n",
    "\n",
    "with sess.graph.as_default():\n",
    "    y = tf.placeholder(tf.float32, shape=(None, dataset_params['nb_classes']))\n",
    "    adv_x_mim = ipermute(mim.generate_np(permute(x_test[0:nb_attacked_images], seed=seed), **mim_params), seed=seed)\n",
    "    preds = model.get_logits(x)\n",
    "adv_acc = model_eval(sess, x, y, preds, permute(adv_x_mim, seed=seed), y_test[0:nb_attacked_images], args=eval_params)\n",
    "print('Accuracy on model {0}:'.format(seed), adv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average l_2 norm perturbation of adversarial examples: 0.9600704516054357\n"
     ]
    }
   ],
   "source": [
    "order = np.inf\n",
    "perturbation_strength = measure_perturbation(x_test[0:nb_attacked_images], adv_x_mim, order=order)\n",
    "print('Average l_{0} norm perturbation of adversarial examples:'.format(order), perturbation_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_attack(attack_name='miml2', adv_x=adv_x_mim, perturbation_strength=perturbation_strength, attack_params=mim_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIM\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on model 100: 0.98\n"
     ]
    }
   ],
   "source": [
    "from cleverhans.attacks import BasicIterativeMethod\n",
    "from cleverhans.utils_tf import model_eval\n",
    "\n",
    "seed = 100 # model for which attack is performed\n",
    "model, sess, x = ensemble.get_model(seed)\n",
    "\n",
    "nb_attacked_images = 100\n",
    "bim = BasicIterativeMethod(model, sess=sess)\n",
    "bim_params = {'eps': .3,\n",
    "              'eps_iter': 0.01,\n",
    "              'ord': np.inf,\n",
    "              'nb_iter': 200}\n",
    "\n",
    "with sess.graph.as_default():\n",
    "    y = tf.placeholder(tf.float32, shape=(None, dataset_params['nb_classes']))\n",
    "    adv_x_bim = ipermute(bim.generate_np(permute(x_test[0:nb_attacked_images], seed=seed), **bim_params), seed=seed)\n",
    "    preds = model.get_logits(x)\n",
    "adv_acc = model_eval(sess, x, y, preds, permute(adv_x_bim, seed=seed), y_test[0:nb_attacked_images], args=eval_params)\n",
    "print('Accuracy on model {0}:'.format(seed), adv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average l_2 norm perturbation of adversarial examples: 0.7575323256883476\n"
     ]
    }
   ],
   "source": [
    "order = bim_params['ord']\n",
    "perturbation_strength = measure_perturbation(x_test[0:nb_attacked_images], adv_x_bim, order=order)\n",
    "print('Average l_{0} norm perturbation of adversarial examples:'.format(order), perturbation_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_attack(attack_name='bim', adv_x=adv_x_bim, perturbation_strength=perturbation_strength, attack_params=bim_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENM\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.attacks import ElasticNetMethod\n",
    "from cleverhans.utils_tf import model_eval\n",
    "\n",
    "seed = 100 # model for which attack is performed\n",
    "model, sess, x = ensemble.get_model(seed)\n",
    "\n",
    "nb_attacked_images = 10000\n",
    "enm = ElasticNetMethod(model, sess=sess)\n",
    "enm_params = {'binary_search_steps': 1,\n",
    "              'max_iterations': 200,\n",
    "              'initial_const': .5,\n",
    "              'beta': 0,\n",
    "              'batch_size': 1}\n",
    "\n",
    "with sess.graph.as_default():\n",
    "    y = tf.placeholder(tf.float32, shape=(None, dataset_params['nb_classes']))\n",
    "    adv_x_enm = ipermute(enm.generate_np(permute(x_test[0:nb_attacked_images], seed=seed), **enm_params), seed=seed)\n",
    "    preds = model.get_logits(x)\n",
    "adv_acc = model_eval(sess, x, y, preds, permute(adv_x_enm, seed=seed), y_test[0:nb_attacked_images], args=eval_params)\n",
    "print('Accuracy on model {0}:'.format(seed), adv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average l_1 norm perturbation of adversarial examples: 4.2946479376344495\n"
     ]
    }
   ],
   "source": [
    "order = 1\n",
    "perturbation_strength = measure_perturbation(x_test[0:nb_attacked_images], adv_x_enm, order=order)\n",
    "print('Average l_{0} norm perturbation of adversarial examples:'.format(order), perturbation_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_attack(attack_name='enm_beta0', adv_x=adv_x_enm, perturbation_strength=perturbation_strength, attack_params=enm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saliency Map Method\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on model 100: 0.887\n"
     ]
    }
   ],
   "source": [
    "from cleverhans.attacks import SaliencyMapMethod\n",
    "from cleverhans.utils_tf import model_eval\n",
    "\n",
    "seed = 100 # model for which attack is performed\n",
    "model, sess, x = ensemble.get_model(seed)\n",
    "\n",
    "nb_attacked_images = 1000\n",
    "smm = SaliencyMapMethod(model, sess=sess)\n",
    "smm_params = {\n",
    "    'theta': 1.,\n",
    "    'gamma': .03\n",
    "}\n",
    "\n",
    "with sess.graph.as_default():\n",
    "    y = tf.placeholder(tf.float32, shape=(None, dataset_params['nb_classes']))\n",
    "    adv_x_smm = ipermute(smm.generate_np(permute(x_test[0:nb_attacked_images], seed=seed), **smm_params), seed=seed)\n",
    "    preds = model.get_logits(x)\n",
    "adv_acc = model_eval(sess, x, y, preds, permute(adv_x_smm, seed=seed), y_test[0:nb_attacked_images], args=eval_params)\n",
    "print('Accuracy on model {0}:'.format(seed), adv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average l_2 norm perturbation of adversarial examples: 2.3036084587919423\n"
     ]
    }
   ],
   "source": [
    "order = 2\n",
    "perturbation_strength = measure_perturbation(x_test[0:nb_attacked_images], adv_x_smm, order=order)\n",
    "print('Average l_{0} norm perturbation of adversarial examples:'.format(order), perturbation_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_attack(attack_name='saliencyl2', adv_x=adv_x_smm, perturbation_strength=perturbation_strength, attack_params=smm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepFool\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleverhans.attacks import DeepFool\n",
    "from cleverhans.utils_tf import model_eval\n",
    "\n",
    "seed = 100 # model for which attack is performed\n",
    "model, sess, x = ensemble.get_model(seed)\n",
    "\n",
    "nb_attacked_images = 10000\n",
    "deep_fool = DeepFool(model, sess=sess)\n",
    "deep_fool_params = {\n",
    "    'nb_candidate': dataset_params['nb_classes'],\n",
    "    'overshoot': 0.1,\n",
    "    'max_iter': 10\n",
    "}\n",
    "\n",
    "with sess.graph.as_default():\n",
    "    y = tf.placeholder(tf.float32, shape=(None, dataset_params['nb_classes']))\n",
    "    adv_x_deep_fool = ipermute(deep_fool.generate_np(permute(x_test[0:nb_attacked_images], seed=seed), **deep_fool_params), seed=seed)\n",
    "    preds = model.get_logits(x)\n",
    "adv_acc = model_eval(sess, x, y, preds, permute(adv_x_deep_fool, seed=seed), y_test[0:nb_attacked_images], args=eval_params)\n",
    "print('Accuracy on model {0}:'.format(seed), adv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average l_2 norm perturbation of adversarial examples: 7.795894422395073\n"
     ]
    }
   ],
   "source": [
    "order = 2\n",
    "perturbation_strength = measure_perturbation(x_test[0:nb_attacked_images], adv_x_deep_fool, order=order)\n",
    "print('Average l_{0} norm perturbation of adversarial examples:'.format(order), perturbation_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_attack(attack_name='deepfooll2', adv_x=adv_x_deep_fool, perturbation_strength=perturbation_strength, attack_params=deep_fool_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EOT with PGD\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacked_models = range(100, 130)\n",
    "TARGET = 0\n",
    "\n",
    "ensemble_logits = []\n",
    "x = tf.placeholder(tf.float32, shape=(1, dataset_params['img_rows'], dataset_params['img_cols'], dataset_params['nb_channels']))\n",
    "for seed in attacked_models:\n",
    "    model, _, _ = ensemble.get_model(seed)\n",
    "    ensemble_logits.append(model.get_logits(x))\n",
    "ensemble_logits = tf.concat(ensemble_logits, axis=0)\n",
    "ensemble_preds = tf.nn.softmax(ensemble_logits)\n",
    "ensemble_labels = tf.tile(tf.expand_dims(tf.one_hot(TARGET, dataset_params['nb_classes']), axis=0), (ensemble_logits.shape[0], 1))\n",
    "ensemble_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=ensemble_logits, labels=ensemble_labels))\n",
    "ensemble_grad, = tf.gradients(ensemble_loss, x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "1\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "2\n",
      "step 0, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "3\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 20, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 30, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 40, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "4\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "5\n",
      "step 0, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 10, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 20, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 30, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "6\n",
      "step 0, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 10, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 20, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "7\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 20, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 30, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "8\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "9\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 30, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 40, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "10\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 20, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "11\n",
      "step 0, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 30, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "12\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "13\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 40, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "14\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 30, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "15\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 20, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "16\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 20, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 30, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 40, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "17\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "18\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 40, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "19\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 40, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "20\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 20, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "21\n",
      "step 0, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 30, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 40, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "22\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "23\n",
      "step 0, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "24\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "25\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 30, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "26\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "27\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 40, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "28\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 20, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "29\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "30\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 40, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "31\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "32\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "33\n",
      "step 0, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 10, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 20, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "34\n",
      "step 0, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 10, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 30, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "35\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 20, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 30, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "36\n",
      "step 0, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 10, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 20, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 30, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "37\n",
      "step 0, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "38\n",
      "step 0, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 10, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "39\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "40\n",
      "step 0, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "41\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 20, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 30, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 40, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "42\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "43\n",
      "step 0, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 10, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 20, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "44\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "45\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 30, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 40, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "46\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "47\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 20, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "48\n",
      "step 0, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 30, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "49\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "50\n",
      "step 0, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 10, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 20, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "51\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 20, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "52\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "53\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "54\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 30, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 40, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "55\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 20, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 30, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "56\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 20, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "57\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 20, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "58\n",
      "step 0, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 10, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "59\n",
      "step 0, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 30, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "60\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "61\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "62\n",
      "step 0, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 10, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 20, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "63\n",
      "step 0, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 40, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "64\n",
      "step 0, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 30, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "65\n",
      "step 0, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 10, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 20, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "66\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 40, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "67\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "68\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 40, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "69\n",
      "step 0, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 10, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 40, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "70\n",
      "step 0, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 40, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "71\n",
      "step 0, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 10, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 20, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 30, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "72\n",
      "step 0, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 10, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 20, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "73\n",
      "step 0, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 30, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "74\n",
      "step 0, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 10, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 20, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "75\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "76\n",
      "step 0, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 10, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "77\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 20, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 30, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "78\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 20, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "79\n",
      "step 0, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 10, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 20, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 30, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "80\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "81\n",
      "step 0, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 10, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 40, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "82\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "83\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 20, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "84\n",
      "step 0, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 10, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 30, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "85\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "86\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "87\n",
      "step 0, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 10, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 20, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 30, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 40, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "88\n",
      "step 0, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 10, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 20, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 30, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 40, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "89\n",
      "step 0, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 10, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 20, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 30, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 40, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "90\n",
      "step 0, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 40, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "91\n",
      "step 0, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 10, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 20, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "92\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "93\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 20, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 30, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 40, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "94\n",
      "step 0, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 30, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 40, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "95\n",
      "step 0, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 10, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 20, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "96\n",
      "step 0, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 10, preds=[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "step 20, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 30, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "97\n",
      "step 0, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "step 10, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "step 20, preds=[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "step 30, preds=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "step 40, preds=[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "98\n",
      "step 0, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 10, preds=[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "step 20, preds=[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "99\n",
      "step 0, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 10, preds=[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "step 20, preds=[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "step 30, preds=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 40, preds=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# PGD\n",
    "\n",
    "LR = .1\n",
    "EPSILON = .3\n",
    "nb_attacked_images = 100\n",
    "\n",
    "tmp = []\n",
    "for j in range(nb_attacked_images):\n",
    "    print(j)\n",
    "    orig = x_test[j:j+1]\n",
    "    adv = np.copy(orig)\n",
    "    lower = np.clip(orig-EPSILON, 0, 1)\n",
    "    upper = np.clip(orig+EPSILON, 0, 1)\n",
    "#     TARGET = (np.argmax(y_test[j]) + 1) % 10\n",
    "    \n",
    "#     ensemble_logits = []\n",
    "#     x = tf.placeholder(tf.float32, shape=(1, dataset_params['img_rows'], dataset_params['img_cols'], dataset_params['nb_channels']))\n",
    "#     for seed in attacked_models:\n",
    "#         model, _, _ = ensemble.get_model(seed)\n",
    "#         ensemble_logits.append(model.get_logits(x))\n",
    "#     ensemble_logits = tf.concat(ensemble_logits, axis=0)\n",
    "#     ensemble_preds = tf.nn.softmax(ensemble_logits)\n",
    "#     ensemble_labels = tf.tile(tf.expand_dims(tf.one_hot(TARGET, dataset_params['nb_classes']), axis=0), (ensemble_logits.shape[0], 1))\n",
    "#     ensemble_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=ensemble_logits, labels=ensemble_labels))\n",
    "#     ensemble_grad, = tf.gradients(ensemble_loss, x)\n",
    "    with tf.Session() as sess:\n",
    "        for i in range(50):\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            g, p= sess.run([ensemble_grad, ensemble_preds], {x: adv})\n",
    "            if i % 10 == 0:\n",
    "                print('step %d, preds=%s' % (i, np.argmax(p, axis=1)))\n",
    "        # step\n",
    "            adv -= LR * g\n",
    "        # project\n",
    "            adv = np.clip(adv, lower, upper)\n",
    "        tmp.append(adv)\n",
    "adv_x = np.concatenate(tmp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average l_inf norm perturbation of adversarial examples: 0.2981751\n"
     ]
    }
   ],
   "source": [
    "order = np.inf\n",
    "perturbation_strength = measure_perturbation(x_test[0:nb_attacked_images], adv_x, order=order)\n",
    "print('Average l_{0} norm perturbation of adversarial examples:'.format(order), perturbation_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adv_x[0].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "p = ensemble.predict(adv_x[0:], seeds=attacked_models)\n",
    "print(np.argmax(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "acc = ensemble.accuracy(adv_x, y_test[0:nb_attacked_images], seeds=range(130,150))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Perturbation Plot Data\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = 'pgdl2'\n",
    "order = 2  # this should be consistent with attack parameters\n",
    "seed = 100  # model for which attack was performed\n",
    "seeds = range(101, 151)  # other models used for ensemble\n",
    "nb_attacked_images = 10000\n",
    "\n",
    "d = read_attack(attack_name = attack_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating random perturbation of x with same power as adversary\n",
    "strength = []\n",
    "adv_acc = []\n",
    "adv_acc_mean_other = []\n",
    "adv_acc_ensemble_other = []\n",
    "\n",
    "rand_acc_mean_other = []\n",
    "rand_acc_ensemble_other = []\n",
    "\n",
    "for perturbation_strength in sorted(d.keys()):\n",
    "    print('calculating stuff for perturbation = ', perturbation_strength)\n",
    "    strength.append(perturbation_strength)\n",
    "    adv_acc.append(ensemble.accuracy(d[perturbation_strength][0:nb_attacked_images], y_test[0:nb_attacked_images], seeds=[seed]))\n",
    "    adv_acc_mean_other.append(np.mean([ensemble.accuracy(d[perturbation_strength][0:nb_attacked_images], y_test[0:nb_attacked_images], seeds=[a]) for a in seeds]))\n",
    "    adv_acc_ensemble_other.append(ensemble.accuracy(d[perturbation_strength][0:nb_attacked_images], y_test[0:nb_attacked_images], seeds=seeds))\n",
    "    \n",
    "    x_random_perturbed = random_perturb(x_test[0:nb_attacked_images], perturbation_strength=perturbation_strength, order=order)\n",
    "    rand_acc_mean_other.append(np.mean([ensemble.accuracy(x_random_perturbed, y_test[0:nb_attacked_images], seeds=[a]) for a in seeds]))\n",
    "    rand_acc_ensemble_other.append(ensemble.accuracy(x_random_perturbed, y_test[0:nb_attacked_images], seeds=seeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c967d5a90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c521b2410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(strength, adv_acc_mean_other, label='adv_acc_mean_other')\n",
    "plt.plot(strength, adv_acc_ensemble_other, label='adv_acc_ensemble_other')\n",
    "plt.plot(strength, rand_acc_mean_other, label='rand_acc_mean_other')\n",
    "plt.plot(strength, rand_acc_ensemble_other, label='rand_acc_ensemble_other')\n",
    "plt.plot(strength, adv_acc, label='adv_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "header=['strength', 'adv_acc', 'adv_acc_mean_other', 'adv_acc_ensemble_other', 'rand_acc_mean_other', 'rand_acc_ensemble_other']\n",
    "arr = [strength, adv_acc, adv_acc_mean_other, adv_acc_ensemble_other, rand_acc_mean_other, rand_acc_ensemble_other]\n",
    "log_plot_data(attack_name=attack_name, header=header, arr=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
